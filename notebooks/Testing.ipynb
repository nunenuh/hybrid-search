{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.join(os.getcwd(), '../', 'src')\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hybrid_search.mapper import DictMapper\n",
    "\n",
    "file_path = '../data/finance_template_map.xlsx'\n",
    "sheet_name = 'Income Statement'\n",
    "dmap = DictMapper(file_path, sheet_name)\n",
    "\n",
    "target_column = 'C'\n",
    "base_source_columns = ['F','G']\n",
    "test_source_columns = ['H','I','J']\n",
    "\n",
    "base_mapping = dmap.create_mapping_dict(base_source_columns, target_column)\n",
    "test_mapping = dmap.create_mapping_dict(test_source_columns, target_column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nunenuh/works/nunenuh/hybrid-search/.venv/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "[nltk_data] Downloading package punkt to /home/nunenuh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/nunenuh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "/home/nunenuh/works/nunenuh/hybrid-search/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from hybrid_search.search import HybridSearch\n",
    "sbert_model_name = \"uonyeka/bge-base-financial-matryoshka\"\n",
    "engine = HybridSearch(base_mapping, transformer_model=sbert_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "CPU times: user 223 ms, sys: 112 μs, total: 223 ms\n",
      "Wall time: 34.8 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'similar_name': 'Net Sales',\n",
       "  'account_name': 'Revenue',\n",
       "  'scores': 2.399999976158142},\n",
       " {'similar_name': 'Net Revenue',\n",
       "  'account_name': 'Revenue',\n",
       "  'scores': 2.123167634010315},\n",
       " {'similar_name': 'Other income, net',\n",
       "  'account_name': 'Other Income',\n",
       "  'scores': 2.045075237751007},\n",
       " {'similar_name': 'Other income/(expense), net',\n",
       "  'account_name': 'Other Income',\n",
       "  'scores': 1.5238357186317444},\n",
       " {'similar_name': 'Purchases', 'account_name': 'Cost of Sales', 'scores': 0.0}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "results = engine.hybrid_search(\"net\", top_n=5, bm25_weight=0.5, transformer_weight=0.9)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "CPU times: user 225 ms, sys: 0 ns, total: 225 ms\n",
      "Wall time: 33.1 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'similar_name': 'Net Sales', 'account_name': 'Revenue', 'scores': 1.0},\n",
       " {'similar_name': 'Net Revenue',\n",
       "  'account_name': 'Revenue',\n",
       "  'scores': 0.72147566},\n",
       " {'similar_name': 'Other income, net',\n",
       "  'account_name': 'Other Income',\n",
       "  'scores': 0.6013825},\n",
       " {'similar_name': 'Other income related to sales',\n",
       "  'account_name': 'Other Operating Income',\n",
       "  'scores': 0.5863799},\n",
       " {'similar_name': 'Cost of Goods Sold',\n",
       "  'account_name': 'Cost of Sales',\n",
       "  'scores': 0.53952223}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "engine.transformer_search(\"net sales\", top_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.13 ms, sys: 228 μs, total: 1.36 ms\n",
      "Wall time: 1.01 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'similar_name': 'Net Sales',\n",
       "  'account_name': 'Revenue',\n",
       "  'scores': 5.205962434179676},\n",
       " {'similar_name': 'Other income related to sales',\n",
       "  'account_name': 'Other Operating Income',\n",
       "  'scores': 2.4724117844051094},\n",
       " {'similar_name': 'Other income, net',\n",
       "  'account_name': 'Other Income',\n",
       "  'scores': 2.247593850770803},\n",
       " {'similar_name': 'Net Revenue',\n",
       "  'account_name': 'Revenue',\n",
       "  'scores': 2.247593850770803},\n",
       " {'similar_name': 'Other income/(expense), net',\n",
       "  'account_name': 'Other Income',\n",
       "  'scores': 2.247593850770803}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "results = engine.bm25_search(\"Net Sales\", top_n=5)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhybrid_search\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m evaluation\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Evaluate and print the results for each search method\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m bm25_eval_results, bm25_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mevaluation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_search_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbm25_search\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBM25 Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbm25_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m transformer_eval_results, transformer_accuracy \u001b[38;5;241m=\u001b[39m evaluation\u001b[38;5;241m.\u001b[39mevaluate_search_accuracy(test_mapping, engine, engine\u001b[38;5;241m.\u001b[39mtransformer_search)\n",
      "File \u001b[0;32m~/works/nunenuh/hybrid-search/notebooks/../src/hybrid_search/evaluation.py:24\u001b[0m, in \u001b[0;36mevaluate_search_accuracy\u001b[0;34m(test_mapping_dict, search_engine, search_method)\u001b[0m\n\u001b[1;32m     <a href='file:///home/nunenuh/works/nunenuh/hybrid-search/notebooks/../src/hybrid_search/evaluation.py?line=21'>22</a>\u001b[0m \u001b[39mfor\u001b[39;00m key, true_value \u001b[39min\u001b[39;00m test_mapping_dict\u001b[39m.\u001b[39mitems():\n\u001b[1;32m     <a href='file:///home/nunenuh/works/nunenuh/hybrid-search/notebooks/../src/hybrid_search/evaluation.py?line=22'>23</a>\u001b[0m     search_results \u001b[39m=\u001b[39m search_method(key, top_n\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='file:///home/nunenuh/works/nunenuh/hybrid-search/notebooks/../src/hybrid_search/evaluation.py?line=23'>24</a>\u001b[0m     predicted_value \u001b[39m=\u001b[39m search_results[\u001b[39m0\u001b[39;49m][\u001b[39m2\u001b[39;49m] \u001b[39mif\u001b[39;00m search_results \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mUnmapped\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='file:///home/nunenuh/works/nunenuh/hybrid-search/notebooks/../src/hybrid_search/evaluation.py?line=24'>25</a>\u001b[0m     is_correct \u001b[39m=\u001b[39m predicted_value \u001b[39m==\u001b[39m true_value\n\u001b[1;32m     <a href='file:///home/nunenuh/works/nunenuh/hybrid-search/notebooks/../src/hybrid_search/evaluation.py?line=25'>26</a>\u001b[0m     \u001b[39mif\u001b[39;00m is_correct:\n",
      "\u001b[0;31mKeyError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "from hybrid_search import evaluation\n",
    "# Evaluate and print the results for each search method\n",
    "bm25_eval_results, bm25_accuracy = evaluation.evaluate_search_accuracy(test_mapping, engine, engine.bm25_search)\n",
    "print(f\"BM25 Accuracy: {bm25_accuracy:.2f}%\")\n",
    "\n",
    "transformer_eval_results, transformer_accuracy = evaluation.evaluate_search_accuracy(test_mapping, engine, engine.transformer_search)\n",
    "print(f\"Transformer Accuracy: {transformer_accuracy:.2f}%\")\n",
    "\n",
    "hybrid_eval_results, hybrid_accuracy = evaluation.evaluate_search_accuracy(test_mapping, engine, engine.hybrid_search)\n",
    "print(f\"Hybrid Accuracy: {hybrid_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Ground Truth</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Financing revenues</td>\n",
       "      <td>Revenue</td>\n",
       "      <td>Revenue</td>\n",
       "      <td>True</td>\n",
       "      <td>3.7364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Producing and manufacturing cost</td>\n",
       "      <td>Cost of Sales</td>\n",
       "      <td>Cost of Sales</td>\n",
       "      <td>True</td>\n",
       "      <td>2.1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Selling, administrative and general</td>\n",
       "      <td>General and Admin Expenses</td>\n",
       "      <td>Sales and Marketing Expenses</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>General and administrative</td>\n",
       "      <td>General and Admin Expenses</td>\n",
       "      <td>General and Admin Expenses</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>employee benefits</td>\n",
       "      <td>General and Admin Expenses</td>\n",
       "      <td>Personnel and Benefit Expenses</td>\n",
       "      <td>False</td>\n",
       "      <td>0.4663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Key                   Predicted  \\\n",
       "0                   Financing revenues                     Revenue   \n",
       "1     Producing and manufacturing cost               Cost of Sales   \n",
       "2  Selling, administrative and general  General and Admin Expenses   \n",
       "3           General and administrative  General and Admin Expenses   \n",
       "4                    employee benefits  General and Admin Expenses   \n",
       "\n",
       "                     Ground Truth  Correct   Score  \n",
       "0                         Revenue     True  3.7364  \n",
       "1                   Cost of Sales     True  2.1997  \n",
       "2    Sales and Marketing Expenses    False  0.5473  \n",
       "3      General and Admin Expenses     True  0.5459  \n",
       "4  Personnel and Benefit Expenses    False  0.4663  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_eval_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix Value:\n",
      "-------------------------\n",
      "True Positive   : 14\n",
      "False Positive  : 12\n",
      "False Negative  : 12\n",
      "True Negative   : 378\n",
      "\n",
      "\n",
      "Evaluation Metrics:\n",
      "--------------------\n",
      "Precision  0.4375\n",
      "Recall     0.4271\n",
      "F1 Score   0.3965\n",
      "Accuracy   0.5385\n"
     ]
    }
   ],
   "source": [
    "# Generate labels for the hybrid search method\n",
    "true_labels, hybrid_predicted_labels = evaluation.generate_labels(test_mapping, engine.hybrid_search)\n",
    "\n",
    "# Print evaluation metrics\n",
    "evaluation.print_evaluation_metrics(true_labels, hybrid_predicted_labels)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2b861c074d615435beae3fed33c5536135f6bfe225ba7aef90a9054278bec251"
  },
  "kernelspec": {
   "display_name": "Python 3.10.12 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
